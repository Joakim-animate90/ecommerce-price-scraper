name: Scheduled Scraping

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual trigger

jobs:
  run-scraper:
    name: Run Price Scraper
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Create .env file
        run: |
          cat > .env <<EOF
          POSTGRES_HOST=${{ secrets.POSTGRES_HOST }}
          POSTGRES_PORT=${{ secrets.POSTGRES_PORT }}
          POSTGRES_DB=${{ secrets.POSTGRES_DB }}
          POSTGRES_USER=${{ secrets.POSTGRES_USER }}
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}
          SCRAPER_CONCURRENT_REQUESTS=16
          SCRAPER_DOWNLOAD_DELAY=2
          LOG_LEVEL=INFO
          EOF
      
      - name: Run scraper with docker-compose
        run: |
          docker-compose up scraper
      
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: scraper-logs
          path: logs/
      
      - name: Notify on failure
        if: failure()
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'Scheduled scraping job failed',
              body: 'The scheduled scraping job failed. Please check the logs.',
              labels: ['bug', 'automated']
            })
